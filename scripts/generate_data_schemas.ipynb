{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerador de Data-Schemas FISCA\n",
    "\n",
    "Este notebook gera automaticamente os arquivos de schema para todas as tabelas do projeto FISCA.\n",
    "\n",
    "## O que este script faz:\n",
    "1. Executa `DESCRIBE FORMATTED` para cada tabela\n",
    "2. Executa `SELECT * LIMIT 10` para cada tabela\n",
    "3. Salva os resultados em arquivos texto e CSV\n",
    "4. Gera documenta√ß√£o para tabelas intermedi√°rias\n",
    "\n",
    "## Tabelas processadas:\n",
    "- **5 tabelas originais** do banco `teste`\n",
    "- **10 tabelas intermedi√°rias** (DataFrames) com documenta√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Acesso ao SparkSession\n",
    "spark = session.sparkSession\n",
    "\n",
    "print(\"‚úì Imports conclu√≠dos\")\n",
    "print(f\"‚úì SparkSession ativa: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√µes\n",
    "DATABASE = \"teste\"\n",
    "OUTPUT_DIR = \"data-schemas\"\n",
    "\n",
    "# Lista de tabelas originais do banco\n",
    "ORIGINAL_TABLES = [\n",
    "    \"fisca_fiscalizacoes_consolidadas\",\n",
    "    \"fisca_dashboard_executivo\",\n",
    "    \"fisca_scores_efetividade\",\n",
    "    \"fisca_metricas_por_afre\",\n",
    "    \"fisca_acompanhamentos\",\n",
    "]\n",
    "\n",
    "print(f\"Database: {DATABASE}\")\n",
    "print(f\"Diret√≥rio de sa√≠da: {OUTPUT_DIR}\")\n",
    "print(f\"Tabelas a processar: {len(ORIGINAL_TABLES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Criar Diret√≥rio de Sa√≠da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria diret√≥rio de sa√≠da\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Diret√≥rio criado: {output_path.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(output_path, table_name, query_type, content):\n",
    "    \"\"\"Salva conte√∫do em arquivo\"\"\"\n",
    "    filename = f\"{table_name}_{query_type}.txt\"\n",
    "    filepath = output_path / filename\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# {table_name} - {query_type}\\n\")\n",
    "        f.write(f\"# Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"# {'='*80}\\n\\n\")\n",
    "        f.write(content)\n",
    "    \n",
    "    print(f\"   ‚úì Salvo: {filename}\")\n",
    "    return filepath\n",
    "\n",
    "print(\"‚úì Fun√ß√µes auxiliares definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Processar Tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rastreamento\n",
    "processed = []\n",
    "failed = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ INICIANDO PROCESSAMENTO\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for table in ORIGINAL_TABLES:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìä Processando: {DATABASE}.{table}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. DESCRIBE FORMATTED\n",
    "        print(\"\\n1Ô∏è‚É£ DESCRIBE FORMATTED...\")\n",
    "        describe_query = f\"DESCRIBE FORMATTED {DATABASE}.{table}\"\n",
    "        print(f\"   Query: {describe_query}\")\n",
    "        \n",
    "        df_describe = spark.sql(describe_query)\n",
    "        describe_result = df_describe.toPandas().to_string(index=False)\n",
    "        save_to_file(output_path, table, \"describe_formatted\", describe_result)\n",
    "        \n",
    "        # 2. SELECT * LIMIT 10\n",
    "        print(\"\\n2Ô∏è‚É£ SELECT * LIMIT 10...\")\n",
    "        select_query = f\"SELECT * FROM {DATABASE}.{table} LIMIT 10\"\n",
    "        print(f\"   Query: {select_query}\")\n",
    "        \n",
    "        df_select = spark.sql(select_query)\n",
    "        df_pandas = df_select.toPandas()\n",
    "        \n",
    "        # Salva TXT\n",
    "        select_result = df_pandas.to_string(index=False)\n",
    "        save_to_file(output_path, table, \"select_limit_10\", select_result)\n",
    "        \n",
    "        # Salva CSV\n",
    "        csv_filename = f\"{table}_sample_data.csv\"\n",
    "        csv_filepath = output_path / csv_filename\n",
    "        df_pandas.to_csv(csv_filepath, index=False, encoding='utf-8')\n",
    "        print(f\"   ‚úì Salvo CSV: {csv_filename}\")\n",
    "        \n",
    "        # 3. Estat√≠sticas\n",
    "        print(\"\\n3Ô∏è‚É£ Estat√≠sticas:\")\n",
    "        print(f\"   - Colunas: {len(df_pandas.columns)}\")\n",
    "        print(f\"   - Linhas (sample): {len(df_pandas)}\")\n",
    "        print(f\"   - Colunas: {', '.join(df_pandas.columns[:5])}...\")\n",
    "        \n",
    "        processed.append(table)\n",
    "        print(f\"\\n‚úÖ {table} processado com sucesso!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERRO: {str(e)}\")\n",
    "        failed.append(table)\n",
    "        \n",
    "        # Salva erro\n",
    "        error_file = output_path / f\"{table}_ERROR.txt\"\n",
    "        with open(error_file, 'w') as f:\n",
    "            f.write(f\"Erro ao processar {table}\\n\")\n",
    "            f.write(f\"Timestamp: {datetime.now()}\\n\")\n",
    "            f.write(f\"Erro: {str(e)}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PROCESSAMENTO DE TABELAS CONCLU√çDO\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gerar Documenta√ß√£o de Tabelas Intermedi√°rias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabelas intermedi√°rias (DataFrames)\n",
    "INTERMEDIATE_TABLES = {\n",
    "    \"metrics_df\": \"Dashboard KPIs - m√©tricas consolidadas\",\n",
    "    \"temporal_df\": \"An√°lise temporal - s√©ries temporais\",\n",
    "    \"gerencia_df\": \"Performance por ger√™ncia\",\n",
    "    \"afre_df\": \"Performance por auditor fiscal\",\n",
    "    \"geo_df\": \"Distribui√ß√£o geogr√°fica\",\n",
    "    \"cnae_df\": \"An√°lise setorial por CNAE\",\n",
    "    \"ml_df\": \"Dataset para machine learning\",\n",
    "    \"network_df\": \"Relacionamentos empresa-auditor-infra√ß√£o\",\n",
    "    \"infraction_types_df\": \"Classifica√ß√£o de tipos de infra√ß√µes\",\n",
    "    \"company_details_df\": \"Detalhes de empresas por CNPJ\",\n",
    "}\n",
    "\n",
    "print(\"\\nüìù Gerando documenta√ß√£o de tabelas intermedi√°rias...\\n\")\n",
    "\n",
    "doc_content = \"# TABELAS INTERMEDI√ÅRIAS (DataFrames in-memory)\\n\\n\"\n",
    "doc_content += f\"Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\"\n",
    "doc_content += \"Estas s√£o tabelas criadas dinamicamente como DataFrames Pandas.\\n\"\n",
    "doc_content += \"N√£o s√£o tabelas persistentes no banco de dados.\\n\\n\"\n",
    "doc_content += f\"{'='*80}\\n\\n\"\n",
    "\n",
    "for table_name, description in INTERMEDIATE_TABLES.items():\n",
    "    doc_content += f\"## {table_name}\\n\"\n",
    "    doc_content += f\"**Descri√ß√£o:** {description}\\n\"\n",
    "    doc_content += f\"**Tipo:** DataFrame Pandas (in-memory)\\n\"\n",
    "    doc_content += f\"**Origem:** Derivado de fisca_fiscalizacoes_consolidadas\\n\\n\"\n",
    "    doc_content += \"**Estrutura:** Consulte src/modules/database.py\\n\\n\"\n",
    "    doc_content += f\"{'-'*80}\\n\\n\"\n",
    "\n",
    "doc_filepath = output_path / \"intermediate_tables_README.txt\"\n",
    "with open(doc_filepath, 'w', encoding='utf-8') as f:\n",
    "    f.write(doc_content)\n",
    "\n",
    "print(f\"‚úì Documenta√ß√£o salva: intermediate_tables_README.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Relat√≥rio Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera relat√≥rio\n",
    "print(\"\\nüìã Gerando relat√≥rio final...\\n\")\n",
    "\n",
    "summary = \"# RELAT√ìRIO DE GERA√á√ÉO DE DATA-SCHEMAS\\n\\n\"\n",
    "summary += f\"Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "summary += f\"Database: {DATABASE}\\n\\n\"\n",
    "summary += f\"## RESUMO\\n\\n\"\n",
    "summary += f\"- Total de tabelas: {len(ORIGINAL_TABLES)}\\n\"\n",
    "summary += f\"- Processadas com sucesso: {len(processed) - len(failed)}\\n\"\n",
    "summary += f\"- Com erro: {len(failed)}\\n\\n\"\n",
    "\n",
    "summary += f\"## TABELAS PROCESSADAS\\n\\n\"\n",
    "for table in processed:\n",
    "    status = \"‚úó\" if table in failed else \"‚úì\"\n",
    "    summary += f\"{status} {table}\\n\"\n",
    "\n",
    "summary += f\"\\n## ARQUIVOS GERADOS\\n\\n\"\n",
    "summary += \"Para cada tabela:\\n\"\n",
    "summary += \"- {table}_describe_formatted.txt\\n\"\n",
    "summary += \"- {table}_select_limit_10.txt\\n\"\n",
    "summary += \"- {table}_sample_data.csv\\n\\n\"\n",
    "\n",
    "summary += \"Documenta√ß√£o adicional:\\n\"\n",
    "summary += \"- intermediate_tables_README.txt\\n\"\n",
    "\n",
    "report_filepath = output_path / \"SUMMARY_REPORT.txt\"\n",
    "with open(report_filepath, 'w', encoding='utf-8') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(summary)\n",
    "print(f\"\\n‚úì Relat√≥rio salvo: {report_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ GERA√á√ÉO DE DATA-SCHEMAS CONCLU√çDA!\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(f\"üìÅ Arquivos salvos em: {output_path.absolute()}\")\n",
    "print(f\"\\nüìä Estat√≠sticas:\")\n",
    "print(f\"   - Tabelas processadas: {len(processed)}\")\n",
    "print(f\"   - Sucesso: {len(processed) - len(failed)}\")\n",
    "print(f\"   - Erros: {len(failed)}\")\n",
    "print(f\"   - Tabelas intermedi√°rias documentadas: {len(INTERMEDIATE_TABLES)}\")\n",
    "\n",
    "if failed:\n",
    "    print(f\"\\n‚ö†Ô∏è Tabelas com erro:\")\n",
    "    for table in failed:\n",
    "        print(f\"   - {table}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. (Opcional) Listar Arquivos Gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista todos os arquivos gerados\n",
    "print(\"\\nüìÇ Arquivos gerados:\\n\")\n",
    "\n",
    "all_files = sorted(output_path.glob(\"*\"))\n",
    "for i, file in enumerate(all_files, 1):\n",
    "    size_kb = file.stat().st_size / 1024\n",
    "    print(f\"{i:2d}. {file.name:50s} ({size_kb:,.1f} KB)\")\n",
    "\n",
    "print(f\"\\nTotal: {len(all_files)} arquivos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
